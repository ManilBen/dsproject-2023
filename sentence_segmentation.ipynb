{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia\n",
        "!pip install wptools\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import nltk \n",
        "nltk.download('punkt')\n",
        "import requests\n",
        "import wikipedia\n",
        "import wptools\n",
        "import os"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yoPp5Jmuv8p",
        "outputId": "3206b2cd-0a2e-481f-f169-fbfc5f144a73"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.11.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.27.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.15)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.4.1)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11696 sha256=63012df9c4db36982366a5f4506e11a9120d031adbd56fb5aba099f28cd855e8\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wptools\n",
            "  Downloading wptools-0.4.17-py2.py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from wptools) (2022.12.7)\n",
            "Collecting pycurl\n",
            "  Downloading pycurl-7.45.2.tar.gz (234 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.2/234.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from wptools) (4.9.2)\n",
            "Collecting html2text\n",
            "  Downloading html2text-2020.1.16-py3-none-any.whl (32 kB)\n",
            "Building wheels for collected packages: pycurl\n",
            "  Building wheel for pycurl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycurl: filename=pycurl-7.45.2-cp310-cp310-linux_x86_64.whl size=338507 sha256=4202eb34ec59bf88a9b7aa2f4f2c8be05180f74f3529d41f01ac0c2a233ac797\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/41/22/c9eb70fde387ea0f16531256570754671f9c8571571982a4c0\n",
            "Successfully built pycurl\n",
            "Installing collected packages: pycurl, html2text, wptools\n",
            "Successfully installed html2text-2020.1.16 pycurl-7.45.2 wptools-0.4.17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scarpper(src, n): #function to get text from web\n",
        "    count = 0 # counter to count that the loop runs n times only\n",
        "    try:\n",
        "        page = wikipedia.page(src) #wikipedia page for the item\n",
        "        l = page.links #get all links from the page\n",
        "        \n",
        "        for link in l: # loop to extract text and make n text files from these wiki links in the said wikipedia page\n",
        "            if count < n+1:\n",
        "                p = wikipedia.page(title = link)\n",
        "                path = '/content/arcs'\n",
        "                file_name = \"{}.txt\".format(p.title)\n",
        "                complete_path = os.path.join(path, file_name)\n",
        "                with open(complete_path, \"w\", encoding= 'utf-8' ) as text_file: # writing text into text files\n",
        "                    text_file.write(p.summary)\n",
        "                count = count +1    \n",
        "            else:\n",
        "                break    \n",
        "            \n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "metadata": {
        "id": "k14C5D30jfTH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first argument 'topic' , second argument 'number for relevant summaries to look for'\n",
        "scarpper('Hubble Space Telescope',30) # executing scarpper function to fetch articles\n",
        "### Topics USED IN THIS CODE: \n",
        "#baseball\n",
        "#meditation\n",
        "#tornadoes\n",
        "#Einstein\n",
        "#archers\n",
        "#Algeria\n",
        "#Native Mexicans\n",
        "#Aztecs\n",
        "#Pyramids\n",
        "#Antarctic krill\n",
        "#Artificial sweetener\n",
        "#Jacques Cousteau\n",
        "#Great Barrier Reef\n",
        "#Frida Kahlo\n",
        "#Mars rover\n",
        "#human rights\n",
        "#Classical conditioning\n",
        "#Hubble Space Telescope"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTxOYfLSkDMN",
        "outputId": "7618acd4-5d76-45a3-9edd-6bd207234747"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/arcs/2I/Borisov.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### reading files from folder and extracting texts\n",
        "def segment_data(directory:str):\n",
        "  ''' the function takes a directory in a string format as an input to read files from a directory then outputs the result in a string format\n",
        "  that is compatible with spacy and nltk for further preprocessing of data.\n",
        "  Then it creates a global object: 'string_text' to be used for other functions if needed.\n",
        "  then the function calls for spacy and nltk to preprocess the text and segment the sentences. THE FINAL OUTPUTS IS :\n",
        "  a global dataframe with four columns that contain:\n",
        "  orignal_text, shared_sentences, unique_to_spacy, unique_to_nltk '''\n",
        "  print('FETCHING ARTICLES FROM DIRECTORY', '*' * 60)\n",
        "  files = os.scandir(directory) # creating an os object \n",
        "  content = []  \n",
        "  print(\"\\nOBJECTS : 'string_text' and 'df' ARE GLOBAL OBJECTS FOR FURTHER MANIPULATION OF YOUR CHOICE\")\n",
        "  for entry in files: # reading each file in the object\n",
        "    if entry.is_file():\n",
        "      with open(entry.path,'r') as f: # opening each file\n",
        "        summaries = f.read()\n",
        "        content.append(summaries) # append text data into content list\n",
        "        ################################\n",
        "        global string_text # making string_text global to be used in other preprocessing functions\n",
        "        string_text = ' '.join(content) # converting all list elements of content object into one long string to be accepted by spacy and nltk\n",
        "  print('\\nDataFrame' , '*' * 60)\n",
        "  nlp = spacy.load('en_core_web_sm')\n",
        "  nlp.max_length = 20000000\n",
        "  spacy_ = nlp(string_text)\n",
        "  spacy_sents1 = [sent.text for sent in spacy_.sents] # creating list of segmented sentences of spacy\n",
        "  print('\\nSpacy Done With No Errors!')\n",
        "  print('*'* 50)\n",
        "  sentences_nltk = nltk.sent_tokenize(string_text) # segmentation nltk\n",
        "  print('Nltk Done With No Errors!')\n",
        "  print('\\nBe careful the resulting dataframe may be unbalanced due to different results from spacy and nltk in the unique sentences:')\n",
        "  global df # making the df global so we can manipulate it after if needed\n",
        "  df = pd.DataFrame()\n",
        "  one_spacy = pd.Series(spacy_sents1)\n",
        "  one_nltk = pd.Series(sentences_nltk)\n",
        "  shared = one_spacy[one_spacy.isin(one_nltk)] # filtering only shared sentences that are segmented the same by the two modules\n",
        "  unique_to_spacy = one_spacy[~one_spacy.isin(one_nltk)] # filtering unique sentences segmented by spacy\n",
        "  unique_to_nltk = one_nltk[~one_nltk.isin(one_spacy)] # filtering unique sentences segmented by spacy\n",
        "  df['shared_sentences'] = shared\n",
        "  df['unique_to_spacy'] = unique_to_spacy.reset_index(drop=True)\n",
        "  df['unique_to_nltk'] = unique_to_nltk.reset_index(drop=True)\n",
        "  df['nltk_segmentation']  = one_nltk.reset_index(drop=True)\n",
        "  df['spacy_segmentation'] = one_spacy.reset_index(drop=True)\n",
        "  df = pd.concat([pd.Series(string_text, name='original_text'), df], axis=1) # create new Series for original text and concatenate with DataFrame  df = df.reset_index(drop=True)\n",
        "  return df"
      ],
      "metadata": {
        "id": "fiG52q-hnXPT"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segment_data('/content/arcs')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 919
        },
        "id": "A6dGMx78nz2Q",
        "outputId": "94ea408a-20b3-4619-a2e0-e26652ad65f0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FETCHING ARTICLES FROM DIRECTORY ************************************************************\n",
            "\n",
            "OBJECTS : 'string_text' and 'df' ARE GLOBAL OBJECTS FOR FURTHER MANIPULATION OF YOUR CHOICE\n",
            "\n",
            "DataFrame ************************************************************\n",
            "\n",
            "Spacy Done With No Errors!\n",
            "**************************************************\n",
            "Nltk Done With No Errors!\n",
            "\n",
            "Be careful the resulting dataframe may be unbalanced due to different results from spacy and nltk in the unique sentences:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          original_text  \\\n",
              "0     Six judges of the International Criminal Court...   \n",
              "1                                                   NaN   \n",
              "2                                                   NaN   \n",
              "3                                                   NaN   \n",
              "4                                                   NaN   \n",
              "...                                                 ...   \n",
              "1503                                                NaN   \n",
              "1504                                                NaN   \n",
              "1506                                                NaN   \n",
              "1509                                                NaN   \n",
              "1510                                                NaN   \n",
              "\n",
              "                                       shared_sentences  \\\n",
              "0     Six judges of the International Criminal Court...   \n",
              "1     The judges were elected for terms of nine year...   \n",
              "2     Accord and satisfaction is a contract law conc...   \n",
              "3     It is one of the methods by which parties to a...   \n",
              "4     The release is completed by the transfer of va...   \n",
              "...                                                 ...   \n",
              "1503                        Voter turnout was only 25%.   \n",
              "1504  The 20th Century Press Archives (German: Press...   \n",
              "1506  It originates from the Hamburg Kolonialinstitu...   \n",
              "1509  In 2007 it was absorbed by the German National...   \n",
              "1510  Article collection was discontinued by end of ...   \n",
              "\n",
              "                                        unique_to_spacy  \\\n",
              "0     If the creditor breaches the accord, then the ...   \n",
              "1     This temple, built by Chola emperor Rajaraja I...   \n",
              "2     The Airavatesvarar temple is one among a clust...   \n",
              "3     It also reverentially displays Vaishnavism and...   \n",
              "4     The stone temple incorporates a chariot struct...   \n",
              "...                                                 ...   \n",
              "1503                                                NaN   \n",
              "1504                                                NaN   \n",
              "1506                                                NaN   \n",
              "1509                                                NaN   \n",
              "1510                                                NaN   \n",
              "\n",
              "                                         unique_to_nltk  \\\n",
              "0     If the creditor breaches the accord, then the ...   \n",
              "1     This temple, built by Chola emperor Rajaraja I...   \n",
              "2     It also reverentially displays Vaishnavism and...   \n",
              "3     It was hypothesized that certain forms, such a...   \n",
              "4     Though challenged in the 17th and 18th centuri...   \n",
              "...                                                 ...   \n",
              "1503                                                NaN   \n",
              "1504                                                NaN   \n",
              "1506                                                NaN   \n",
              "1509                                                NaN   \n",
              "1510                                                NaN   \n",
              "\n",
              "                                      nltk_segmentation  \\\n",
              "0     Six judges of the International Criminal Court...   \n",
              "1     The judges were elected for terms of nine year...   \n",
              "2     Accord and satisfaction is a contract law conc...   \n",
              "3     It is one of the methods by which parties to a...   \n",
              "4     The release is completed by the transfer of va...   \n",
              "...                                                 ...   \n",
              "1503                                                NaN   \n",
              "1504                                                NaN   \n",
              "1506                                                NaN   \n",
              "1509                                                NaN   \n",
              "1510                                                NaN   \n",
              "\n",
              "                                     spacy_segmentation  \n",
              "0     Six judges of the International Criminal Court...  \n",
              "1     The judges were elected for terms of nine year...  \n",
              "2     Accord and satisfaction is a contract law conc...  \n",
              "3     It is one of the methods by which parties to a...  \n",
              "4     The release is completed by the transfer of va...  \n",
              "...                                                 ...  \n",
              "1503                        Voter turnout was only 25%.  \n",
              "1504  The 20th Century Press Archives (German: Press...  \n",
              "1506  It originates from the Hamburg Kolonialinstitu...  \n",
              "1509  In 2007 it was absorbed by the German National...  \n",
              "1510  Article collection was discontinued by end of ...  \n",
              "\n",
              "[1042 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c354d486-6492-49ed-8e1c-eec19980ebc6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_text</th>\n",
              "      <th>shared_sentences</th>\n",
              "      <th>unique_to_spacy</th>\n",
              "      <th>unique_to_nltk</th>\n",
              "      <th>nltk_segmentation</th>\n",
              "      <th>spacy_segmentation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Six judges of the International Criminal Court...</td>\n",
              "      <td>Six judges of the International Criminal Court...</td>\n",
              "      <td>If the creditor breaches the accord, then the ...</td>\n",
              "      <td>If the creditor breaches the accord, then the ...</td>\n",
              "      <td>Six judges of the International Criminal Court...</td>\n",
              "      <td>Six judges of the International Criminal Court...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>The judges were elected for terms of nine year...</td>\n",
              "      <td>This temple, built by Chola emperor Rajaraja I...</td>\n",
              "      <td>This temple, built by Chola emperor Rajaraja I...</td>\n",
              "      <td>The judges were elected for terms of nine year...</td>\n",
              "      <td>The judges were elected for terms of nine year...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Accord and satisfaction is a contract law conc...</td>\n",
              "      <td>The Airavatesvarar temple is one among a clust...</td>\n",
              "      <td>It also reverentially displays Vaishnavism and...</td>\n",
              "      <td>Accord and satisfaction is a contract law conc...</td>\n",
              "      <td>Accord and satisfaction is a contract law conc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>It is one of the methods by which parties to a...</td>\n",
              "      <td>It also reverentially displays Vaishnavism and...</td>\n",
              "      <td>It was hypothesized that certain forms, such a...</td>\n",
              "      <td>It is one of the methods by which parties to a...</td>\n",
              "      <td>It is one of the methods by which parties to a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>The release is completed by the transfer of va...</td>\n",
              "      <td>The stone temple incorporates a chariot struct...</td>\n",
              "      <td>Though challenged in the 17th and 18th centuri...</td>\n",
              "      <td>The release is completed by the transfer of va...</td>\n",
              "      <td>The release is completed by the transfer of va...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1503</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Voter turnout was only 25%.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Voter turnout was only 25%.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1504</th>\n",
              "      <td>NaN</td>\n",
              "      <td>The 20th Century Press Archives (German: Press...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The 20th Century Press Archives (German: Press...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1506</th>\n",
              "      <td>NaN</td>\n",
              "      <td>It originates from the Hamburg Kolonialinstitu...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>It originates from the Hamburg Kolonialinstitu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1509</th>\n",
              "      <td>NaN</td>\n",
              "      <td>In 2007 it was absorbed by the German National...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>In 2007 it was absorbed by the German National...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1510</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Article collection was discontinued by end of ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Article collection was discontinued by end of ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1042 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c354d486-6492-49ed-8e1c-eec19980ebc6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c354d486-6492-49ed-8e1c-eec19980ebc6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c354d486-6492-49ed-8e1c-eec19980ebc6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('segmentation_data.csv',index=False) # save the dataframe into a csv"
      ],
      "metadata": {
        "id": "JRhgto1O7PdD"
      },
      "execution_count": 33,
      "outputs": []
    }
  ]
}